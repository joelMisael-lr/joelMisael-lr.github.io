<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Unidad 4 - Computación Paralela</title>
  <style>
    body { 
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
      margin: 0; 
      padding: 0; 
      background-color: #f5f7fa;
      color: #333;
      line-height: 1.6;
    }
    
    header { 
      background: linear-gradient(135deg, #003366, #005599);
      color: white; 
      padding: 30px 20px; 
      text-align: center; 
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    
    h1 {
      margin: 0;
      font-size: 2.2em;
      text-shadow: 1px 1px 3px rgba(0,0,0,0.3);
    }
    
    nav {
      display: flex;
      background: #005599;
      justify-content: center;
      padding: 15px;
      flex-wrap: wrap;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    nav a {
      color: white;
      text-decoration: none;
      padding: 12px 25px;
      margin: 5px 10px;
      background: #0077cc;
      border-radius: 30px;
      font-weight: 500;
      transition: all 0.3s ease;
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }
    
    nav a:hover {
      background: #0066b3;
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    .container {
      max-width: 1200px;
      margin: 30px auto;
      padding: 0 20px;
    }
    
    .section {
      background: white;
      border-radius: 8px;
      padding: 25px;
      margin-bottom: 30px;
      box-shadow: 0 2px 15px rgba(0,0,0,0.05);
      border-left: 5px solid #0077cc;
    }
    
    .section h2 {
      color: #005599;
      margin-top: 0;
      border-bottom: 2px solid #e1e5eb;
      padding-bottom: 10px;
    }
    
    .subsection {
      margin-left: 20px;
      padding-left: 15px;
      border-left: 3px solid #e1e5eb;
    }
    
    .subsection h3 {
      color: #0077cc;
    }
    
    .subsection h4 {
      color: #0099ff;
    }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      box-shadow: 0 1px 10px rgba(0,0,0,0.05);
    }
    
    th, td {
      padding: 12px 15px;
      text-align: left;
      border-bottom: 1px solid #e1e5eb;
    }
    
    th {
      background-color: #0077cc;
      color: white;
      font-weight: 500;
    }
    
    tr:nth-child(even) {
      background-color: #f8fafc;
    }
    
    tr:hover {
      background-color: #f1f5f9;
    }
    
    .image-container {
      text-align: center;
      margin: 25px 0;
    }
    
    .image-container img {
      max-width: 100%;
      height: auto;
      border-radius: 6px;
      box-shadow: 0 4px 15px rgba(0,0,0,0.1);
      border: 1px solid #e1e5eb;
    }
    
    .image-container figcaption {
      margin-top: 10px;
      font-style: italic;
      color: #666;
      font-size: 0.9em;
    }
    
    .card-container {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      margin: 20px 0;
    }
    
    .card {
      flex: 1 1 300px;
      background: white;
      border-radius: 8px;
      padding: 20px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.08);
      border-top: 4px solid #0077cc;
      transition: transform 0.3s ease;
    }
    
    .card:hover {
      transform: translateY(-5px);
      box-shadow: 0 8px 20px rgba(0,0,0,0.1);
    }
    
    .card h3 {
      color: #005599;
      margin-top: 0;
    }
    
    .comparison-table {
      width: 100%;
      margin: 25px 0;
    }
    
    .comparison-table th {
      background: #005599;
      color: white;
      text-align: center;
    }
    
    .comparison-table td {
      text-align: center;
      vertical-align: middle;
    }
    
    .feature-icon {
      font-size: 24px;
      margin-bottom: 10px;
      color: #0077cc;
    }
    
    .architecture-diagram {
      background: #f8fafc;
      padding: 20px;
      border-radius: 8px;
      margin: 25px 0;
      text-align: center;
    }
    
    .parallel-types {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
      gap: 20px;
      margin: 25px 0;
    }
    
    .parallel-card {
      background: linear-gradient(145deg, #ffffff, #f0f4f8);
      border-radius: 10px;
      padding: 25px;
      box-shadow: 0 6px 15px rgba(0,0,0,0.05);
      border-top: 4px solid #0077cc;
      transition: all 0.3s ease;
    }
    
    .parallel-card:hover {
      transform: translateY(-5px);
      box-shadow: 0 10px 25px rgba(0,0,0,0.1);
    }
    
    .memory-hierarchy {
      background: #e6f2ff;
      padding: 20px;
      border-radius: 8px;
      margin: 25px 0;
      border-left: 4px solid #0077cc;
    }
    
    .network-types {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
      margin: 25px 0;
    }
    
    .network-card {
      flex: 1 1 400px;
      background: white;
      border-radius: 8px;
      padding: 20px;
      box-shadow: 0 4px 10px rgba(0,0,0,0.08);
      border-top: 4px solid #0099ff;
    }
    
    .case-study {
      background: #f9f9f9;
      padding: 25px;
      border-radius: 8px;
      margin: 25px 0;
      border-left: 4px solid #005599;
    }
    
    .case-study h3 {
      color: #005599;
      margin-top: 0;
    }
    
    .highlight-box {
      background: #e6f2ff;
      padding: 20px;
      border-radius: 8px;
      margin: 25px 0;
      border-left: 4px solid #0077cc;
    }
    
    @media (max-width: 768px) {
      .card-container, .network-types {
        flex-direction: column;
      }
      
      .parallel-types {
        grid-template-columns: 1fr;
      }
    }
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
</head>
<body>
  <header>
    <h1>Arquitectura de Computadoras - Unidad 4 </h1>
  </header>
  
  <nav>
    <a href="index.html"><i class="fas fa-home"></i> Inicio</a>
    <a href="unidad1.html"><i class="fas fa-microchip"></i> Unidad 1</a>
    <a href="unidad2.html"><i class="fas fa-cogs"></i> Unidad 2</a>
    <a href="unidad 3.html"><i class="fas fa-laptop-code"></i> Unidad 3</a>
    <a href="unidad 4.html"><i class="fas fa-server"></i> Unidad 4</a>
    <a href="practicas.html"><i class="fas fa-flask"></i> Prácticas</a>
  </nav>

  <div class="container">
    <section class="section">
      <h2>4.1 Aspectos Básicos de la Computación Paralela</h2>
      
      <div class="image-container">
        <img src="paralelaVSsecuencial.png" alt="Computación Paralela vs Secuencial">
        <figcaption>Figura 4.1: Comparación entre computación paralela y secuencial</figcaption>
      </div>
      
      <div class="card-container">
        <div class="card">
          <h3>Definición</h3>
          <p>La computación paralela es el uso simultáneo de múltiples recursos computacionales para resolver un problema, dividiéndolo en partes independientes que pueden ejecutarse concurrentemente.</p>
        </div>
        
        <div class="card">
          <h3>Objetivos</h3>
          <ul>
            <li>Reducir tiempo de ejecución</li>
            <li>Aumentar throughput</li>
            <li>Resolver problemas más grandes</li>
            <li>Mejorar eficiencia energética</li>
          </ul>
        </div>
        
        <div class="card">
          <h3>Ley de Amdahl</h3>
          <p>El speedup máximo que se puede lograr está limitado por la parte secuencial del programa:</p>
          <p><strong>Speedup = 1 / (S + P/N)</strong></p>
          <p>Donde S es la parte secuencial, P la paralelizable y N el número de procesadores.</p>
        </div>
      </div>
      
      <div class="highlight-box">
        <h3>Principios Fundamentales</h3>
        <ul>
          <li><strong>Descomposición:</strong> Dividir el problema en tareas independientes</li>
          <li><strong>Asignación:</strong> Distribuir tareas a procesadores</li>
          <li><strong>Coordinación:</strong> Sincronización y comunicación</li>
          <li><strong>Escalabilidad:</strong> Capacidad de crecer con más recursos</li>
        </ul>
      </div>
    </section>

    <section class="section">
      <h2>4.2 Tipos de Computación Paralela</h2>
      
      <div class="subsection">
        <h3>4.2.1 Clasificación</h3>
        
        <div class="parallel-types">
          <div class="parallel-card">
            <h4><i class="fas fa-layer-group"></i> Paralelismo a Nivel de Bit</h4>
            <p>Aumento del tamaño de palabra (de 32 a 64 bits)</p>
            <ul>
              <li>Mayor precisión</li>
              <li>Más datos por operación</li>
            </ul>
          </div>
          
          <div class="parallel-card">
            <h4><i class="fas fa-code"></i> Paralelismo a Nivel de Instrucción</h4>
            <p>Ejecución simultánea de múltiples instrucciones (pipelining, superscalar)</p>
            <ul>
              <li>CPI < 1</li>
              <li>Dependencia de datos</li>
            </ul>
          </div>
          
          <div class="parallel-card">
            <h4><i class="fas fa-tasks"></i> Paralelismo a Nivel de Tarea</h4>
            <p>División del programa en hilos o procesos independientes</p>
            <ul>
              <li>Multithreading</li>
              <li>Multiprocesamiento</li>
            </ul>
          </div>
          
          <div class="parallel-card">
            <h4><i class="fas fa-network-wired"></i> Paralelismo a Nivel de Programa</h4>
            <p>Ejecución concurrente de programas independientes</p>
            <ul>
              <li>Multiusuario</li>
              <li>Multitarea</li>
            </ul>
          </div>
        </div>
      </div>
      
      <div class="subsection">
        <h3>4.2.2 Arquitectura de Computadoras Secuenciales</h3>
        
        <div class="architecture-diagram">
          <img src="vonNeuman.png" alt="Arquitectura secuencial de Von Neumann">
          <figcaption>Figura 4.2: Arquitectura secuencial tradicional de Von Neumann</figcaption>
        </div>
        
        <table class="comparison-table">
          <tr>
            <th>Característica</th>
            <th>Ventajas</th>
            <th>Limitaciones</th>
          </tr>
          <tr>
            <td>Flujo secuencial</td>
            <td>Simple de implementar</td>
            <td>Cuello de botella en CPU</td>
          </tr>
          <tr>
            <td>Memoria compartida</td>
            <td>Fácil programación</td>
            <td>Contención de memoria</td>
          </tr>
          <tr>
            <td>Unidad de control única</td>
            <td>Determinista</td>
            <td>Escalabilidad limitada</td>
          </tr>
        </table>
      </div>
      
      <div class="subsection">
        <h3>4.2.3 Organización de Direcciones de Memoria</h3>
        
        <div class="memory-hierarchy">
          <h4>Jerarquía de Memoria en Sistemas Paralelos</h4>
          <ol>
            <li><strong>Registros:</strong> Acceso en 1 ciclo</li>
            <li><strong>Cache L1/L2:</strong> 2-10 ciclos</li>
            <li><strong>Cache L3 compartida:</strong> 20-40 ciclos</li>
            <li><strong>Memoria principal:</strong> 100-300 ciclos</li>
            <li><strong>Discos/SSD:</strong> 10,000+ ciclos</li>
          </ol>
        </div>
        
        <div class="card-container">
          <div class="card">
            <h4>Memoria Uniforme (UMA)</h4>
            <ul>
              <li>Todos los procesadores ven la misma latencia</li>
              <li>Arquitecturas SMP</li>
              <li>Fácil de programar</li>
            </ul>
          </div>
          
          <div class="card">
            <h4>Memoria No Uniforme (NUMA)</h4>
            <ul>
              <li>Latencia depende de ubicación</li>
              <li>Mayor escalabilidad</li>
              <li>Requiere conciencia de localidad</li>
            </ul>
          </div>
        </div>
        
        <div class="image-container">
          <img src="umaVSnuma.png" alt="UMA vs NUMA">
          <figcaption>Figura 4.3: Comparación entre arquitecturas UMA y NUMA</figcaption>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>4.3 Sistemas de Memoria Compartida</h2>
      
      <div class="subsection">
        <h3>4.3.1 Redes de Interconexión Dinámicas ó Indirectas</h3>
        
        <div class="highlight-box">
          <p>Las redes dinámicas permiten conexiones flexibles entre procesadores y memoria mediante mecanismos de conmutación.</p>
        </div>
        
        <div class="subsection">
          <h4>4.3.1.1 Redes de Medio Compartido</h4>
          
          <div class="network-types">
            <div class="network-card">
              <h4>Bus Compartido</h4>
              <ul>
                <li>Un único canal de comunicación</li>
                <li>Arbitraje necesario</li>
                <li>Limitado a pocos procesadores</li>
                <li>Ejemplo: Bus frontal en multicore</li>
              </ul>
            </div>
            
            <div class="network-card">
              <h4>Anillo</h4>
              <ul>
                <li>Nodos conectados en círculo</li>
                <li>Mensajes pasan de nodo a nodo</li>
                <li>Latencia proporcional a N</li>
                <li>Ejemplo: Intel Ring Bus</li>
              </ul>
            </div>
          </div>
        </div>
        
        <div class="subsection">
          <h4>4.3.1.2 Redes Conmutadas</h4>
          
          <div class="network-types">
            <div class="network-card">
              <h4>Crossbar</h4>
              <ul>
                <li>Conexión completa N×M</li>
                <li>Sin contención</li>
                <li>Coste O(N²)</li>
                <li>Ejemplo: GPUs high-end</li>
              </ul>
            </div>
            
            <div class="network-card">
              <h4>Multietapa (Omega, Butterfly)</h4>
              <ul>
                <li>Log N etapas de conmutadores 2×2</li>
                <li>Coste O(N log N)</li>
                <li>Permite conexiones simultáneas</li>
                <li>Usado en supercomputadoras</li>
              </ul>
            </div>
          </div>
          
          <div class="image-container">
            <img src="TiposdeRedes.png" alt="Redes dinámicas de interconexión">
            <figcaption>Figura 4.4: Tipos de redes dinámicas de interconexión</figcaption>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>4.4 Sistemas de Memoria Distribuida: Multiprocesadores</h2>
      
      <div class="architecture-diagram">
        <img src="MemoriaDistribuida.png" alt="Arquitectura de memoria distribuida">
        <figcaption>Figura 4.5: Arquitectura típica de un multiprocesador de memoria distribuida</figcaption>
      </div>
      
      <div class="subsection">
        <h3>4.4.1 Redes de Interconexión Estáticas</h3>
        
        <table class="comparison-table">
          <tr>
            <th>Tipo</th>
            <th>Grado</th>
            <th>Diámetro</th>
            <th>Bisectriz</th>
            <th>Aplicación</th>
          </tr>
          <tr>
            <td>Malla 2D</td>
            <td>4</td>
            <td>2(√N-1)</td>
            <td>√N</td>
            <td>Clusters</td>
          </tr>
          <tr>
            <td>Toro</td>
            <td>4</td>
            <td>√N</td>
            <td>2√N</td>
            <td>Blue Gene</td>
          </tr>
          <tr>
            <td>Hipercubo</td>
            <td>log N</td>
            <td>log N</td>
            <td>N/2</td>
            <td>Antiguas CM</td>
          </tr>
          <tr>
            <td>Árbol</td>
            <td>3</td>
            <td>2 log N</td>
            <td>1</td>
            <td>Cloud</td>
          </tr>
        </table>
        
        <div class="card-container">
          <div class="card">
            <h4>Ventajas</h4>
            <ul>
              <li>Mayor escalabilidad</li>
              <li>Ancho de banda agregado</li>
              <li>Menor contención</li>
            </ul>
          </div>
          
          <div class="card">
            <h4>Desventajas</h4>
            <ul>
              <li>Programación más compleja</li>
              <li>Overhead de comunicación</li>
              <li>Balanceo de carga crítico</li>
            </ul>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <h2>4.5 Casos de Estudio</h2>
      
      <div class="case-study">
        <h3>Supercomputadora Fugaku</h3>
        <div class="card-container">
          <div class="card">
            <h4>Especificaciones</h4>
            <ul>
              <li>7,630,848 núcleos</li>
              <li>Arquitectura ARM A64FX</li>
              <li>Memoria HBM2</li>
              <li>Rendimiento: 442 PetaFLOPS</li>
            </ul>
          </div>
          <div class="card">
            <h4>Arquitectura</h4>
            <ul>
              <li>Memoria distribuida</li>
              <li>Red Tofu interconexión 6D</li>
              <li>NUMA avanzado</li>
            </ul>
          </div>
        </div>
        <div class="image-container">
          <img src="Fugaku.png" alt="Arquitectura Fugaku">
          <figcaption>Figura 4.6: Supercomputadora Fugaku</figcaption>
        </div>
      </div>
      
      <div class="case-study">
        <h3>GPU NVIDIA A100</h3>
        <div class="card-container">
          <div class="card">
            <h4>Especificaciones</h4>
            <ul>
              <li>6,912 CUDA cores</li>
              <li>432 Tensor cores</li>
              <li>40GB HBM2e</li>
              <li>1,555 GB/s bandwidth</li>
            </ul>
          </div>
          <div class="card">
            <h4>Arquitectura Paralela</h4>
            <ul>
              <li>Memoria compartida</li>
              <li>Jerarquía de hilos/blocks</li>
              <li>NVLink para multi-GPU</li>
            </ul>
          </div>
        </div>
        <div class="highlight-box">
          <h4>Aplicaciones</h4>
          <p>IA, HPC, análisis de datos, simulaciones científicas, renderizado</p>
        </div>
      </div>
      
      <div class="case-study">
        <h3>Cluster Google Borg</h3>
        <div class="card-container">
          <div class="card">
            <h4>Escala</h4>
            <ul>
              <li>Miles de máquinas</li>
              <li>Millones de jobs/día</li>
              <li>Alta disponibilidad</li>
            </ul>
          </div>
          <div class="card">
            <h4>Arquitectura</h4>
            <ul>
              <li>Memoria distribuida</li>
              <li>Balanceo de carga</li>
              <li>Tolerancia a fallos</li>
            </ul>
          </div>
        </div>
        <div class="image-container">
          <img src="sistemaBorgdeGoogle.png" alt="Arquitectura Borg">
          <figcaption>Figura 4.7: Arquitectura del sistema Borg de Google</figcaption>
        </div>
      </div>
    </section>
  </div>
</body>
</html>
